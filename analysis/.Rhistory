position = position_dodge(width = 0.5), width = 0.3) +
facet_wrap(~ exp_inf,
labeller = as_labeller(c(`0` = "baseline", `1` = "low", `2` = "high")))
ggplot(ggpredictions_class, aes(x = mean_rating, y = predicted)) +
geom_point(aes(color = wm), position = position_dodge(width = 0.5)) +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high, color = wm),
position = position_dodge(width = 0.5), width = 0.3) +
facet_wrap(~ exp_inf,
labeller = as_labeller(c(`0` = "baseline", `1` = "low", `2` = "high"))) +
#scale_fill_brewer(palette = "Set2") +
theme_classic()
data_check <- data_or_rm[!is.na(data_or_rm$condition),] %>% group_by(ID, prime_order) %>% slice(1)
data_check %>% as.matrix() %>% as.data.frame() %>%
group_by(wm, genre, prime_order) %>% tally() %>% arrange(wm, genre, prime_order)
data_olm %>%
ggplot(aes(x = condition, fill = mean_rating)) +
geom_bar(position = "fill") +
facet_grid(genre ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load",                                                   'rock' = "rock", 'classical' = "classical"))) +
scale_fill_brewer(palette = "Set2") +
theme_classic()
# odds ratio & ci
exp(cbind(OR = coef(class_olmm), confint(class_olmm)))
# get the summary of the model
summary(class_olmm)
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_pres + wm*exp_inf + (1|ID),
data = data_olm[???])
class_olmm <- clmm(mean_rating ~ wm + exp_inf + wm*exp_inf + (1|ID),
data = data_olm[data_olm$genre=="classical",])
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_pres + wm*exp_inf + (1|ID),
data = data_olm[data_olm$genre=="classical",])
data_olm
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_exp + wm*exp_inf + (1|ID),
data = data_olm[data_olm$genre=="classical",])
# get the summary of the model
summary(class_olmm)
class_olmm2 <- clmm(mean_rating ~ wm + exp_inf + wm*exp_inf + (1|ID),
data = data_olm[data_olm$genre=="classical",])
anova(class_olmm,class_olmm2)
# generate predictions from the model
ggpredictions_class <- data.frame(ggpredict(class_olmm, terms = c("wm", "exp_inf"), type = "fe"))
# get the summary of the model
summary(class_olmm2)
# odds ratio & ci
exp(cbind(OR = coef(class_olmm), confint(class_olmm)))
anova(class_olmm2)
class_olmm2
anova(class_olmm2, test = "Chisq")
anova(class_olmm2, test = "Chisq")
data_prep <- data_or_rm %>%
mutate(ID = as.factor(ID),
wm = factor(wm),
# condition should already be a factor, ordered by "baseline", "low", "high"
# for consistency with the paper,
# let's use a variable in place of `conditions` called `explicit information`:
exp_inf = factor(case_when(#condition == "baseline" ~ 0,
condition == "low" ~ 1,
condition == "high" ~ 2)),
genre = factor(genre, levels = c("classical","rock")),
# let's add a variable for `repeated exposure`:
rep_exp = factor(case_when(condition == "baseline" ~ 0,
prime_order == 1 & condition == "high" ~ 1,
prime_order == 1 & condition == "low" ~ 2,
prime_order == 2 & condition == "high" ~ 2,
prime_order == 2 & condition == "low" ~ 1)))
str(data_prep) # examine the structure of the data
data_olm <- data_prep[!is.na(data_or_rm$rating),] %>%
group_by(ID, condition, genre) %>%
mutate(mean_rating = round(mean(rating)), .after = rating) %>%
ungroup %>%
mutate(mean_rating = factor(mean_rating, ordered = TRUE),
rating = factor(rating, ordered = TRUE))
data_olm %>%
ggplot(aes(x = condition, fill = mean_rating)) +
geom_bar(position = "fill") +
facet_grid(genre ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load",                                                   'rock' = "rock", 'classical' = "classical"))) +
scale_fill_brewer(palette = "Set2") +
theme_classic()
str(data_olm)
class_olmm <- clmm(mean_rating ~ wm + exp_inf + wm*exp_inf+ (1|ID),
data = data_olm[data_olm$genre=="classical",])
class_olmm <- clmm(mean_rating ~ wm + exp_inf + wm*exp_inf+ (1|ID),
data = data_olm[data_olm$genre=="classical" & !is.na(data_olm$exp_inf),])
# get the summary of the model
summary(class_olmm2)
data_prep <- data_or_rm %>%
mutate(ID = as.factor(ID),
wm = factor(wm),
# condition should already be a factor, ordered by "baseline", "low", "high"
# for consistency with the paper,
# let's use a variable in place of `conditions` called `explicit information`:
exp_inf = factor(case_when(condition == "baseline" ~ NA,
condition == "low" ~ 1,
condition == "high" ~ 2)),
genre = factor(genre, levels = c("classical","rock")),
# let's add a variable for `repeated exposure`:
rep_exp = factor(case_when(condition == "baseline" ~ 0,
prime_order == 1 & condition == "high" ~ 1,
prime_order == 1 & condition == "low" ~ 2,
prime_order == 2 & condition == "high" ~ 2,
prime_order == 2 & condition == "low" ~ 1)))
data_prep <- data_or_rm %>%
mutate(ID = as.factor(ID),
wm = factor(wm),
# condition should already be a factor, ordered by "baseline", "low", "high"
# for consistency with the paper,
# let's use a variable in place of `conditions` called `explicit information`:
exp_inf = factor(case_when(#condition == "baseline" ~ NA,
condition == "low" ~ 0,
condition == "high" ~ 1)),
genre = factor(genre, levels = c("classical","rock")),
# let's add a variable for `repeated exposure`:
rep_exp = factor(case_when(condition == "baseline" ~ 0,
prime_order == 1 & condition == "high" ~ 1,
prime_order == 1 & condition == "low" ~ 2,
prime_order == 2 & condition == "high" ~ 2,
prime_order == 2 & condition == "low" ~ 1)))
str(data_prep) # examine the structure of the data
data_olm <- data_prep[!is.na(data_or_rm$rating),] %>%
group_by(ID, condition, genre) %>%
mutate(mean_rating = round(mean(rating)), .after = rating) %>%
ungroup %>%
mutate(mean_rating = factor(mean_rating, ordered = TRUE),
rating = factor(rating, ordered = TRUE))
str(data_olm)
data_olm %>%
ggplot(aes(x = exp_inf, fill = mean_rating)) +
geom_bar(position = "fill") +
facet_grid(genre ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load",                                                   'rock' = "rock", 'classical' = "classical"))) +
scale_fill_brewer(palette = "Set2") +
theme_classic()
data_class <- data_olm[data_olm$genre=="classical",]
data_class[!is.na(data_class$exp_inf),]
class_olmm <- clmm(mean_rating ~ wm + exp_inf + wm*exp_inf+ (1|ID),
data = data_class[!is.na(data_class$exp_inf),])
# get the summary of the model
summary(class_olmm)
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_exp + wm*exp_inf+ (1|ID),
data = data_class[!is.na(data_class$exp_inf),])
# get the summary of the model
summary(class_olmm)
# odds ratio & ci
exp(cbind(OR = coef(class_olmm), confint(class_olmm)))
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_exp + wm*exp_inf+ (1|ID),
data = data_class[!is.na(data_class$exp_inf),])
# get the summary of the model
summary(class_olmm)
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_exp + wm*exp_inf+ (1|ID),
data = data_class[!is.na(data_class$exp_inf),], nAGQ = 10)
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_exp + (1|ID),
data = data_class[!is.na(data_class$exp_inf),], nAGQ = 10)
# get the summary of the model
summary(class_olmm)
data_prep <- data_or_rm %>%
mutate(ID = as.factor(ID),
wm = factor(wm),
# condition should already be a factor, ordered by "baseline", "low", "high"
# for consistency with the paper,
# let's use a variable in place of `conditions` called `explicit information`:
exp_inf = factor(case_when(condition == "baseline" ~ 2,
condition == "low" ~ 0,
condition == "high" ~ 1)),
genre = factor(genre, levels = c("classical","rock")),
# let's add a variable for `repeated exposure`:
rep_exp = factor(case_when(condition == "baseline" ~ 0,
prime_order == 1 & condition == "high" ~ 1,
prime_order == 1 & condition == "low" ~ 2,
prime_order == 2 & condition == "high" ~ 2,
prime_order == 2 & condition == "low" ~ 1)))
str(data_prep) # examine the structure of the data
data_olm <- data_prep[!is.na(data_or_rm$rating),] %>%
group_by(ID, condition, genre) %>%
mutate(mean_rating = round(mean(rating)), .after = rating) %>%
ungroup %>%
mutate(mean_rating = factor(mean_rating, ordered = TRUE),
rating = factor(rating, ordered = TRUE))
str(data_olm)
data_olm %>%
ggplot(aes(x = exp_inf, fill = mean_rating)) +
geom_bar(position = "fill") +
facet_grid(genre ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load",                                                   'rock' = "rock", 'classical' = "classical"))) +
scale_fill_brewer(palette = "Set2") +
theme_classic()
data_olm %>%
ggplot(aes(x = exp_inf, fill = mean_rating)) +
geom_bar(position = "fill") +
facet_grid(genre ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load",                                                   'rock' = "rock", 'classical' = "classical"))) +
scale_fill_brewer(palette = "Set2") +
scale_x_continuous(labels = c("low","high","baseline")) +
theme_classic()
data_olm %>%
ggplot(aes(x = exp_inf, fill = mean_rating)) +
geom_bar(position = "fill") +
facet_grid(genre ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load",                                                   'rock' = "rock", 'classical' = "classical"))) +
scale_fill_brewer(palette = "Set2") +
scale_x_discrete(labels = c("low","high","baseline")) +
theme_classic()
data_class <- data_olm[data_olm$genre=="classical",]
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_exp + (1|ID),
data = data_class)
# get the summary of the model
summary(class_olmm)
# odds ratio & ci
exp(cbind(OR = coef(class_olmm), confint(class_olmm)))
-3.6865 - (1.1481)
exp(-3.6865 - (1.1481))
1+exp(-3.6865 - (1.1481))
exp(-3.6865 - (1.1481))/1.00795
exp(-3.6865 - (1.1481))/(1+exp(-3.6865 - (1.1481)))
class_olmm <- clmm(mean_rating ~ wm + exp_inf + rep_exp + wm*exp_inf + (1|ID),
data = data_class)
class_olmm <- clmm(mean_rating ~ wm + exp_inf + wm*exp_inf + (1|ID),
data = data_class)
# get the summary of the model
summary(class_olmm)
-3.5118 - 1.14548
exp(-4.65728)
exp(-4.65728)/(1+exp(-4.65728))
plogis(-4.65728)
# generate predictions from the model
ggpredictions_class <- data.frame(ggpredict(class_olmm, terms = c("wm", "exp_inf"), type = "fe"))
ggpredictions_class$x = factor(ggpredictions_class$x)
colnames(ggpredictions_class)[c(1, 6,7)] <- c("wm", "mean_rating", "exp_inf")
ggplot(ggpredictions_class, aes(x = exp_inf, y = predicted, fill = mean_rating)) +
geom_bar(position = "fill", stat = "identity") +
geom_bar(position = "fill") +
facet_grid(genre ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load",                                                   'rock' = "rock", 'classical' = "classical"))) +
scale_fill_brewer(palette = "Set2") +
scale_x_discrete(labels = c("low","high","baseline")) +
theme_classic()
ggpredictions_class
ggplot(ggpredictions_class, aes(x = exp_inf, y = predicted, fill = mean_rating)) +
geom_bar(position = "fill", stat = "identity") +
#geom_bar(position = "fill") +
facet_grid(. ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load"))) +
scale_fill_brewer(palette = "Set2") +
scale_x_discrete(labels = c("low","high","baseline")) +
theme_classic()
ggplot(ggpredictions_class, aes(x = exp_inf, y = predicted, fill = mean_rating)) +
#geom_bar(position = "fill", stat = "identity") +
geom_bar(position = "fill") +
facet_grid(. ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load"))) +
scale_fill_brewer(palette = "Set2") +
scale_fill_manual(values = cbPalette) +
scale_x_discrete(labels = c("low","high","baseline")) +
theme_classic() +
ggtitle("Probabilities of responses, full model")
ggplot(ggpredictions_class, aes(x = exp_inf, y = predicted, fill = mean_rating)) +
#geom_bar(position = "fill", stat = "identity") +
geom_bar(position = "fill") +
facet_grid(. ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load"))) +
scale_fill_brewer(palette = "Set2") +
scale_x_discrete(labels = c("low","high","baseline")) +
theme_classic() +
ggtitle("Probabilities of responses, full model")
ggplot(ggpredictions_class, aes(x = exp_inf, y = predicted, fill = mean_rating)) +
geom_bar(position = "fill", stat = "identity") +
facet_grid(. ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load"))) +
scale_fill_brewer(palette = "Set2") +
scale_x_discrete(labels = c("low","high","baseline")) +
theme_classic() +
ggtitle("Probabilities of responses, full model")
class_olmm <- clmm(mean_rating ~ wm + exp_inf+ (1|ID),
data = data_class)
# get the summary of the model
summary(class_olmm)
# generate predictions from the model
ggpredictions_class <- data.frame(ggpredict(class_olmm, terms = c("wm", "exp_inf"), type = "fe"))
# clean up
ggpredictions_class$x = factor(ggpredictions_class$x)
colnames(ggpredictions_class)[c(1, 6,7)] <- c("wm", "mean_rating", "exp_inf")
ggpredictions_class
ggplot(ggpredictions_class, aes(x = mean_rating, y = predicted)) +
geom_point(aes(color = wm), position = position_dodge(width = 0.5)) +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high, color = wm),
position = position_dodge(width = 0.5), width = 0.3) +
facet_wrap(~ exp_inf,
labeller = as_labeller(c(`0` = "baseline", `1` = "low", `2` = "high"))) +
#scale_fill_brewer(palette = "Set2") +
theme_classic()
ggplot(ggpredictions_class, aes(x = exp_inf, y = predicted, fill = mean_rating)) +
geom_bar(position = "fill", stat = "identity") +
facet_grid(. ~ wm,
labeller = as_labeller(c(`0` = "no load", `1` = "load"))) +
scale_fill_brewer(palette = "Set2") +
scale_x_discrete(labels = c("low","high","baseline")) +
theme_classic() +
ggtitle("Probabilities of responses, full model")
sjPlot::tab_model(class_olmm)
setwd("~/Repos/RRI_analysis/analysis")
# ----
# Load and prepare data
library(tidyverse)
options(dplyr.summarise.inform = FALSE)
# set path to current directory
data_path <- c('../../RRI_data_materials/data')
source('funs.R') # two functions you need in this script
all_data <- list.files(data_path, pattern = ".csv") # all csv files
filtered_data <- filter_data(all_data) # filter for complete & true data sets
View(wrangle_data)
# This script takes raw data files (from a directory at ../../RRI_data_materials/data') and
# cleans them up so that at the end you have
# - a single data file with all relevant data, and
# - a file of demographic data for demographic analysis
# This was used by Ava Kiai to generate the final data files used in EXPRA Group 6's
# experiment, on 11/02/2022.
# ----
# Load and prepare data
library(tidyverse)
options(dplyr.summarise.inform = FALSE)
# set path to current directory
data_path <- c('../../RRI_data_materials/data')
source('funs.R') # two functions you need in this script
all_data <- list.files(data_path, pattern = ".csv") # all csv files
filtered_data <- filter_data(all_data) # filter for complete & true data sets
# NEW!
filtered_data_files <- filtered_data$file_names
participant_breakdown <- filtered_data$participant_breakdown
print(paste("N =", length(filtered_data_files)))
# ----
# Wrangle Data
# The wrangle_data() function cleans up the raw data into a single dataframe for the main data,
# and a dataframe for demographic information (this will be useful for calculating an index of
# musical ability using the Goldsmiths Musical Sophistical Index we implemented at the start of the experiment).
wrangled_data <- wrangle_data(data_path, filtered_data_files)
data <- wrangled_data$data %>% mutate(question_n = factor(question_n, labels = c("Interpretation","Timing/Rhythm","Tone Quality","Expressiveness"))) # make a better label for the question index
demographics <- wrangled_data$demgraphics
# -----
# Save Data
# Take a moment to familiarize yourself with the structure of the data.
# Save the data as-is for easier reference. This snippet of code will also create a folder, `\data` in the main `RRI_analysis` folder, if none already exists.
data_save <- c("../data")
dir.create(data_save, showWarnings = FALSE)
write.csv(data, file.path(data_save, "data.csv"), row.names = FALSE)
write.csv(demographics, file.path(data_save, "demographic_data.csv"), row.names = FALSE)
#Now, in the future, you can simple load the `data.csv` file for analysis.
head(data)
debugSource("~/Repos/RRI_analysis/analysis/funs.R")
wrangled_data <- wrangle_data(data_path, filtered_data_files)
this_struct.full
this_struct
this_maindata
# compile
this_data2 <- cbind(
rbind(this_struct.full[1:(nrow(this_struct.full)/2),], matrix(rep(c("NA", this_struct.full[1,2], "NA", "NA"),3), ncol = 4, byrow = TRUE),
this_struct.full[(nrow(this_struct.full)/2+1):nrow(this_struct.full),], matrix(rep(c("NA", this_struct.full[nrow(this_struct.full),2], "NA", "NA"),3), ncol = 4, byrow = TRUE)),
this_maindata) %>% as.data.frame()
this_data2
this_data2 %>%
setNames(c("condition", "genre", "prime_order", "probe", "question_n" ,"question", "rating", "open_text", "final_eval")) %>%
q]
this_data2 %>%
setNames(c("condition", "genre", "prime_order", "probe", "question_n" ,"question", "rating", "open_text", "final_eval"))
this_data3 <- this_data2 %>%
setNames(c("condition", "genre", "prime_order", "probe", "question_n" ,"question", "rating", "open_text", "final_eval")) %>%
mutate(knew_piece = rep(this_knew, each = nrow(this_data2)/2)) %>%
mutate(ID = this_demogdata$ID, .before = 1) %>%
mutate(EXPRA = this_demogdata$EXPRA_code,
sex = this_demogdata$sex,
age = this_demogdata$age)
this_data3
# working memory
wm_data <- cbind(this_data$wm_recall_response.text,this_data$confidence_resp.response)[which(this_data$wm_recall_response.text!=""),]
if (is.null(wm_data)) {
this_data3 <- this_data3 %>% mutate(wm = 0, .after = "probe")
this_data4 <- this_data3 %>% mutate(wm_response = NA, .after = "wm") %>% mutate(confidence = NA, .after = "wm_response")
} else {
this_data3 <- this_data3 %>% mutate(wm = 1, .after = "probe")
wm_data <- wm_data[2:nrow(wm_data),]
wm_data.full <- matrix(rep(wm_data, each = 6), ncol=ncol(wm_data), byrow = FALSE)
wm_data.paste <- rbind(wm_data.full[1:(nrow(wm_data.full)/2),], matrix(rep(rep("NA",2),3), ncol = 2, byrow = TRUE),
wm_data.full[(nrow(wm_data.full)/2+1):nrow(wm_data.full),], matrix(rep(rep("NA", 2),3), ncol = 2, byrow = TRUE)) %>%
as.data.frame() %>%
setNames(c("wm_response", "confidence"))
this_data4 <- this_data3 %>% add_column(wm_data.paste, .after = "wm")
}
this_data4
# working memory
wm_data <- cbind(this_data$wm_recall_response.text,this_data$confidence_resp.response)[which(this_data$wm_recall_response.text!=""),]
if (is.null(wm_data)) {
this_data3 <- this_data3 %>% mutate(wm = 0, .after = "probe")
this_data4 <- this_data3 %>% mutate(wm_response = NA, .after = "wm") %>% mutate(confidence = NA, .after = "wm_response")
} else {
this_data3 <- this_data3 %>% mutate(wm = 1, .after = "probe")
wm_data <- wm_data[2:nrow(wm_data),]
wm_data.full <- matrix(rep(wm_data, each = 6), ncol=ncol(wm_data), byrow = FALSE)
wm_data.paste <- rbind(wm_data.full[1:(nrow(wm_data.full)/2),], matrix(rep(rep("NA",2),3), ncol = 2, byrow = TRUE),
wm_data.full[(nrow(wm_data.full)/2+1):nrow(wm_data.full),], matrix(rep(rep("NA", 2),3), ncol = 2, byrow = TRUE)) %>%
as.data.frame() %>%
setNames(c("wm_response", "confidence"))
this_data4 <- this_data3 %>% add_column(wm_data.paste, .after = "wm")
}
this_data3
is.null(wm_data)
wm_data
this_data3 <- this_data3 %>% mutate(wm = 1, .after = "probe")
wm_data <- wm_data[2:nrow(wm_data),]
wm_data.full <- matrix(rep(wm_data, each = 6), ncol=ncol(wm_data), byrow = FALSE)
wm_data.paste <- rbind(wm_data.full[1:(nrow(wm_data.full)/2),], matrix(rep(rep("NA",2),3), ncol = 2, byrow = TRUE),
wm_data.full[(nrow(wm_data.full)/2+1):nrow(wm_data.full),], matrix(rep(rep("NA", 2),3), ncol = 2, byrow = TRUE)) %>%
as.data.frame() %>%
setNames(c("wm_response", "confidence"))
this_data4 <- this_data3 %>% add_column(wm_data.paste, .after = "wm")
this_data4
#fctrs <- c("condition","genre","prime_order","question","question_n")
#numcs <- c("age","sex","confidence","rating","final_eval","knew_piece","wm")
data <- rbind(data, this_data4) #%>% mutate(across(all_of(fctrs), as.factor),
data
data
unique(data$final_eval)
debugSource("~/Repos/RRI_analysis/analysis/funs.R")
# This script takes raw data files (from a directory at ../../RRI_data_materials/data') and
# cleans them up so that at the end you have
# - a single data file with all relevant data, and
# - a file of demographic data for demographic analysis
# This was used by Ava Kiai to generate the final data files used in EXPRA Group 6's
# experiment, on 11/02/2022.
# ----
# Load and prepare data
library(tidyverse)
options(dplyr.summarise.inform = FALSE)
# set path to current directory
data_path <- c('../../RRI_data_materials/data')
source('funs.R') # two functions you need in this script
all_data <- list.files(data_path, pattern = ".csv") # all csv files
filtered_data <- filter_data(all_data) # filter for complete & true data sets
# NEW!
filtered_data_files <- filtered_data$file_names
participant_breakdown <- filtered_data$participant_breakdown
print(paste("N =", length(filtered_data_files)))
# ----
# Wrangle Data
# The wrangle_data() function cleans up the raw data into a single dataframe for the main data,
# and a dataframe for demographic information (this will be useful for calculating an index of
# musical ability using the Goldsmiths Musical Sophistical Index we implemented at the start of the experiment).
wrangled_data <- wrangle_data(data_path, filtered_data_files)
data <- wrangled_data$data %>% mutate(question_n = factor(question_n, labels = c("Interpretation","Timing/Rhythm","Tone Quality","Expressiveness"))) # make a better label for the question index
demographics <- wrangled_data$demgraphics
# -----
# Save Data
# Take a moment to familiarize yourself with the structure of the data.
# Save the data as-is for easier reference. This snippet of code will also create a folder, `\data` in the main `RRI_analysis` folder, if none already exists.
data_save <- c("../data")
dir.create(data_save, showWarnings = FALSE)
write.csv(data, file.path(data_save, "data.csv"), row.names = FALSE)
write.csv(demographics, file.path(data_save, "demographic_data.csv"), row.names = FALSE)
#Now, in the future, you can simple load the `data.csv` file for analysis.
source("~/Repos/RRI_analysis/analysis/funs.R")
# This script takes raw data files (from a directory at ../../RRI_data_materials/data') and
# cleans them up so that at the end you have
# - a single data file with all relevant data, and
# - a file of demographic data for demographic analysis
# This was used by Ava Kiai to generate the final data files used in EXPRA Group 6's
# experiment, on 11/02/2022.
# ----
# Load and prepare data
library(tidyverse)
options(dplyr.summarise.inform = FALSE)
# set path to current directory
data_path <- c('../../RRI_data_materials/data')
source('funs.R') # two functions you need in this script
all_data <- list.files(data_path, pattern = ".csv") # all csv files
filtered_data <- filter_data(all_data) # filter for complete & true data sets
# NEW!
filtered_data_files <- filtered_data$file_names
participant_breakdown <- filtered_data$participant_breakdown
print(paste("N =", length(filtered_data_files)))
# ----
# Wrangle Data
# The wrangle_data() function cleans up the raw data into a single dataframe for the main data,
# and a dataframe for demographic information (this will be useful for calculating an index of
# musical ability using the Goldsmiths Musical Sophistical Index we implemented at the start of the experiment).
wrangled_data <- wrangle_data(data_path, filtered_data_files)
data <- wrangled_data$data %>% mutate(question_n = factor(question_n, labels = c("Interpretation","Timing/Rhythm","Tone Quality","Expressiveness"))) # make a better label for the question index
demographics <- wrangled_data$demgraphics
# -----
# Save Data
# Take a moment to familiarize yourself with the structure of the data.
# Save the data as-is for easier reference. This snippet of code will also create a folder, `\data` in the main `RRI_analysis` folder, if none already exists.
data_save <- c("../data")
dir.create(data_save, showWarnings = FALSE)
write.csv(data, file.path(data_save, "data.csv"), row.names = FALSE)
write.csv(demographics, file.path(data_save, "demographic_data.csv"), row.names = FALSE)
#Now, in the future, you can simple load the `data.csv` file for analysis.
unique(data$final_eval)
View(data)
# load tidyverse
library(tidyverse)
# if you don't already have the following packages, then run:
#install.packages(c("sjPlot","ordinal","ggeffects"))
library(sjPlot) # for generating a nice summary table
library(ordinal) # for ordinal logistic regression
library(ggeffects) # will also install and load package "emmmeans"
options(dplyr.summarise.inform = FALSE)
# set path to current directory
data_path <- c('../data')
# load data
data <- read.csv(file.path(data_path,'data.csv')) %>%
mutate(condition = factor(condition, levels = c("baseline","low","high")))
print(paste("N =", length(unique(data$ID))))
head(data)
unique(data$final_eval)
